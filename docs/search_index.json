[["index.html", "Holo-omics workbook", " Holo-omics workbook Holo-omics overview. Modified from Nyholm et al. 2020 [1] The Holo-omics workbook is a compilation of methodological procedures to generate, analyse and integrate holo-omic data, i.e., multi-omic data jointly generated from hosts and associated microbial communities [1, 2]. This resource extends the contents of the article “A practical introduction to holo-omics”, which aims at guiding researchers to the main critical steps and decision points to perform holo-omic studies. While the article focuses on discussing pros and cons of using multiple available options, the aim of the workbook is to compile protocols and pipelines to be implemented by researchers. The Holo-omics Workbook is presented in two formats: Website (https://holo-omics.github.io/) PDF document (https://holo-omics.github.io/holo-omics_workbook.pdf) These resources are presented as two of the main final outputs of the H2020 project HoloFood. More information about this EU Innovation Action that ran between 2019 and 2023 can be found in the HoloFood section in this workbook, the HoloFood Website and the CORDIS website. Contents Introduction: general information about holo-omics, employed data types and study design considerations. Laboratory procedures: methods and procedures for generating raw omic data of hosts and microbial communities. Bioinformatic procedures: methods and procedures for processing raw omic data into quantitative datasets to be analysed through statistics. Statistical procedures: methods and procedures for analysing and integrating holo-omic data. Protocols, exercises and tutorials The workbook contains example data and bits of code (mostly shell and R) to reproduce data generation and analysis procedures. Code boxes look like the following: shao4d_perm &lt;- shao4d %&gt;% tax_transform(&quot;identity&quot;, rank = &quot;genus&quot;) %&gt;% dist_calc(&quot;aitchison&quot;) %&gt;% dist_permanova( variables = c(&quot;birth_mode&quot;, &quot;sex&quot;, &quot;number_reads&quot;), n_perms = 99, # you should use more permutations in your real analyses! n_processes = 1 ) #&gt; Dropping samples with missings: 15 #&gt; 2022-11-24 01:15:20 - Starting PERMANOVA with 99 perms with 1 processes #&gt; 2022-11-24 01:15:21 - Finished PERMANOVA shao4d_perm %&gt;% perm_get() #&gt; Permutation test for adonis under reduced model #&gt; Marginal effects of terms #&gt; Permutation: free #&gt; Number of permutations: 99 #&gt; #&gt; vegan::adonis2(formula = formula, data = metadata, permutations = n_perms, by = by, parallel = parall) #&gt; Df SumOfSqs R2 F Pr(&gt;F) #&gt; birth_mode 1 10462 0.09055 29.3778 0.01 ** #&gt; sex 1 402 0.00348 1.1296 0.31 #&gt; number_reads 1 1117 0.00967 3.1364 0.01 ** #&gt; Residual 287 102209 0.88462 #&gt; Total 290 115540 1.00000 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Authors Antton Alberdi (*corresponding author), University of Copenhagen Morten T Limborg, University of Copenhagen Iñaki Odriozola, University of Copenhagen Jacob A Rasmussen, University of Copenhagen Protocol and script contributors Carlotta Pietroni, University of Copenhagen Raphael Eisenhofer, University of Copenhagen Jorge Langa, University of Copenhagen Other relevant people Tom Gilbert (HoloFood project coordinator), University of Copenhagen Anna Fotaki (HoloFood project manager), University of Copenhagen How to cite this work Instructions to cite this work will be eventually added. Acknowledgement This project has received funding from the European Unionʼs Horizon 2020 research and innovation programme under grant agreement No 817729. References "],["holo-omics.html", "1 Introduction to holo-omics", " 1 Introduction to holo-omics Holo-omics refers to the methodological approach that jointly generates and analyses multi-omic data from hosts and associated microbial communities [1]. The holo-omic approach to host-microbiota interactions relies on three major assumptions: Host-associated microorganisms interact not only with each other but also with their host [3]. These interactions affect, either positively or negatively, central biological processes of hosts and microorganisms [4]. The interplay can be traced using biomolecular tools. References "],["omic-layers.html", "1.1 Omic layers", " 1.1 Omic layers Nucleic acid sequencing and mass spectrometry technologies that enable tracking the biomolecular pathways linking host and mi- crobial genomic sequences with biomolecular phenotypes by generating (meta)transcriptomes, (meta) proteomes, and (meta)metabolomes. The same technologies also enable epigenomic and exposomic profiling, which can further contribute to disentangling the biochemical associations between host-micro- biota-environment interactions and their effect on host phenotypes In this workbook we consider seven omic layers that require specific data generation and analysis strategies before integrating them into multi-omic statistical models: Nucleic acid sequencing-based Host genomics - HG Host transcriptomics - HT Microbial metagenomics - MG Microbial metatranscriptomics - MT Mass spectrometry-based Host proteomics - HP Microbial metaproteomics - MP (Meta)metabolomics - ME Acknowledging the distinct biological and structural characteristics of these seven omic layers is essential to design experiments and analytical pipelines for better solving the complex puzzle of host-microbiota interactions. "],["host-genomics.html", "1.2 Host genomics (HG)", " 1.2 Host genomics (HG) Contents to be added "],["host-transcriptomics.html", "1.3 Host transcriptomics (HT)", " 1.3 Host transcriptomics (HT) Contents to be added "],["microbial-metagenomics.html", "1.4 Microbial metagenomics (MG)", " 1.4 Microbial metagenomics (MG) Contents to be added "],["microbial-metatranscriptomics.html", "1.5 Microbial metatranscriptomics (MT)", " 1.5 Microbial metatranscriptomics (MT) Contents to be added "],["host-proteomics.html", "1.6 Host proteomics (HP)", " 1.6 Host proteomics (HP) Contents to be added "],["microbial-metaproteomics.html", "1.7 Microbial metaproteomics (MP)", " 1.7 Microbial metaproteomics (MP) Contents to be added "],["meta-metabolomics.html", "1.8 (Meta)metabolomics (ME)", " 1.8 (Meta)metabolomics (ME) Contents to be added "],["holofood.html", "2 HoloFood", " 2 HoloFood HoloFood is a hologenomic approach that will improve the efficiency of food production systems by understanding the biomolecular and physiological processes affected by incorporating feed additives and novel sustainable feeds in farmed animals. The HoloFood consortium will showcase the potential of an innovative solution that holds enormous potential for optimising modern food production. Specifically, HoloFood is a framework that integrates a suite of recent analytical and technological developments, that is applicable to any major animal food production system, spanning the full production line. Thus it is as relevant for the farmers producing livestock, as it is to the associate industries such as those producing the feed and feed additives upon which the animal’s growth, quality, health and wellbeing depends. Methodological point of view With the planet’s population rapidly increasing, one of the key global challenges of this century is to secure that the growing food production is performed in a sustainable fashion and with a low-carbon signature. Hence, optimising food production is thus not only of commercial interest for companies, but also of critical importance for humanity. In the last decades, and in particular since the 2006 ban of using antibiotics to promote animal growth in the European Union, different strategies are being developed to modulate gut microbiomes aiming to improve food production, such as functional feed components or feed additives.Feed additives have been proven effective at modulating microbiomes in many animal systems, although their efficiency often exhibits large variation. The likely reason underlying such inconsistency, is the very limited knowledge we have about the specific means of action of the additives. Understanding the effect of these additives is poorly understood, because the microorganisms of interest might interact with hundreds of other microbial taxa as well as the host organism. Consequently, the procedures to improve the feed additive products are not as efficient as they could be, and it is unlikely that any truly optimal product can be found without drastically modifying the approach taken. The holo-omic approach considers the holobiont (host animal and its associated microbiota) as a single unit of action, across multiple molecular levels. ​To achieve this, HoloFood takes advantage of large variety of new technological developments that allow us to understand the interactions between the animal and their respective gut microbiome on numerous molecular levels. In addition to this genetic data, HoloFood also incorporates a lot more information to the dataset, such as physiological and health information. "],["about-labwork.html", "3 About labwork", " 3 About labwork Laboratory protocols Nucleic-acid sequencing-based approaches DNA/RNA extraction for HG, HT, MG and MT Sequencing library preparation for HG and MG Sequencing library preparation for HT Sequencing library preparation for MT Mass spectrometry-based approaches Protein extraction for HP and MP Metabolite extraction for ME "],["dna-rna-extraction.html", "4 DNA/RNA extraction", " 4 DNA/RNA extraction Hundreds or (probably) thousands of different protocols and variations exist for extracting and purifying nucleic acids. Protocols can be classified based on methodological (e.g., chemical vs. physical DNA/RNA isolation, column-based vs bead-based, commercial vs. open-access). Sample preprocessing Bead-beating Contents to be added Freeze-heat shock Contents to be added Tissue digestion Contents to be added Chemical isolation Based on chemical separation of nucleic acids from the rest of molecules. Physicochemical isolation Based on physical separation of nucleic acids from the rest of molecules. Column-based Contents to be added Bead-based Contents to be added Available protocols Contents to be added "],["protein-metabolite-extraction.html", "5 Protein/metabolite extraction", " 5 Protein/metabolite extraction Laboratory protocols for protein/metabolite extraction "],["sequencing-library-preparation.html", "6 Sequencing library preparation", " 6 Sequencing library preparation Laboratory protocols "],["subheading.html", "6.1 Subheading", " 6.1 Subheading Test text "],["about-bioinformatics.html", "7 About bioinformatics", " 7 About bioinformatics Bioinformatic processing of raw sequencing and mass spectrometry data is the computational step that precedes statistical analyses and integration of multi-omic data. Through bioinformatic processing raw data are converted into meaningful bits of information, usually drastically decreasing the size of the data sets that are used for downstream analyses. Raw sequencing and mass spectrometry-based data files used in holo-omic analyses are typically in the realm of gigabytes (Gb) or even terabytes (Tb). Many of the performed operations require large amounts of memory (some more than 1Tb), which makes it impossible to process data in personal computers. Instead, most bioinformatics tasks are performed in computational clusters with access to large amounts of memory and many CPUs and GPUs, which enable parallelising computational tasks thus speeding up data processing time. However, for the sake of simplicity and practicality, the example datasets included in this Workbook have been considerably downscaled to enable reproducing the exercises in personal computers. All bioinformatic analyses included in the Holo-omics workbook are conducted in a Unix command line Shell environment (BASH/SH). You can find the details to set-up your SHELL environment in the section Prepare your R environment. "],["prepare-shell.html", "7.1 Prepare your shell environment", " 7.1 Prepare your shell environment Content to be added. Required software Content to be added. Pipeline management Content to be added. Install software in conda environment Content to be added. #Example code goes here "],["example-data-bioinformatics.html", "7.2 Example data for bioinformatics", " 7.2 Example data for bioinformatics Contents to be added here. #Example code goes here "],["sequencing-data-preprocessing.html", "8 Sequencing data preprocessing", " 8 Sequencing data preprocessing Here is a review of existing methods. "],["host-genomics-data-processing.html", "9 Host genomics (HG) data processing", " 9 Host genomics (HG) data processing Contents to be added. "],["host-reference-genome.html", "9.1 Host reference genome", " 9.1 Host reference genome Contents to be added. "],["host-genome-resequencing.html", "9.2 Host genome resequencing", " 9.2 Host genome resequencing Contents to be added. "],["microbial-metagenomics-data-processing.html", "10 Microbial metagenomics (MG) data processing", " 10 Microbial metagenomics (MG) data processing Contents to be added. "],["reference-based.html", "10.1 Reference-based", " 10.1 Reference-based Assembly-based. "],["genome-resolved.html", "10.2 Genome-resolved", " 10.2 Genome-resolved Contents to be added. "],["genome-resolved-1.html", "10.3 Genome-resolved", " 10.3 Genome-resolved Contents to be added. "],["host-transcriptomics-data-processing.html", "11 Host transcriptomics (HT) data processing", " 11 Host transcriptomics (HT) data processing Contents to be added. "],["microbial-metatranscriptomics-data-processing.html", "12 Microbial metatranscriptomics (HT) data processing", " 12 Microbial metatranscriptomics (HT) data processing Contents to be added. "],["host-proteomics-data-processing.html", "13 Host proteomics (HP) data processing", " 13 Host proteomics (HP) data processing Contents to be added. "],["microbial-metaproteomics-data-processing.html", "14 Microbial metaproteomics (MP) data processing", " 14 Microbial metaproteomics (MP) data processing Contents to be added. "],["about-statistics.html", "15 About statistics", " 15 About statistics Statistics is probably the most challenging step of holo-omic studies, due to two main factors: the extreme complexity of the data, often containing thousands of features, and the limited sample size, often in the realm of the dozens of sampling units. This combination renders many holo-omic datasets rather statistics unfriendly. A step-by-step approach In this workbook we strongly encourage researchers to proceed step-by-step when dealing with holo-omics data and biological questions. Initial quantitative exploration of omic layers The analysis of any multi-omic data should begin with independent analysis of each omic layer to learn about its structure and variability before jumping to multi-omic data integration. Data transformations: multivariate datasets consist of different data types (e.g., presence-absence of taxa, counts of genes, community-level metabolic capacity index of a function, concentrations of metabolites across samples) that may require specific transformation before applying statistical techniques. Unsupervised exploration of omic layers: include exploratory techniques, such as cluster analysis and ordination-based visualisation methods, which reveal the structure and main patterns of the omic datasets without prior information about experimental design. These procedures might reveal that the observations are structured into meaningful groups or that variables can be reduced to fewer dimensions. Supervised analysis of omic layers: this type of analyses incorporate information of experimental design and aim at testing and estimating the effects of the experimental factors (e.g., dietary treatment, drug administration) or variables of interest (e.g., age of the experimental subjects, geographic location of studied populations) on different omic layers. Multi-omic data integration When it comes to multi-omic data integration, the approaches can be broadly categorised into two types: multi-staged analysis and meta-dimensional or simultaneous analysis. Multi-staged integration: leverages the central dogma of molecular biology to assume that the variation in omic datasets is hierarchical, such that variation in DNA leads to variation in RNA and so on to determine the phenotype Meta-dimensional integration: considers the possibility that the phenotype is the product of the combination of variation across all omic layers, with the presence of complex inter-omic interactions. All statistical analyses included in the Holo-omics workbook are conducted in R environment. You can find the details to set-up your R environment in the section Prepare your R environment. "],["prepare-r.html", "15.1 Prepare your R environment", " 15.1 Prepare your R environment All statistical analyses included in the Holo-omics workbook are conducted in R environment [5]. R is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of UNIX platforms, Windows and MacOS, and in order to use it, R or RStudio must be installed in your local computer or remote server. Required packages In order to reproduce the analyses shown in the workbook, a rather long list of R packages must be installed. Packages are the fundamental units of reproducible R code, which include reusable R functions, the documentation that describes how to use them, and sample data. ape DESeq2 distillR ggplot2 tidyverse vegan (…) Package installation Packages are installed programatically using three main ways: through CRAN, Bioconductor or Github. Install package from CRAN CRAN is a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R. Packages stored in CRAN can be installed using the following code: install.packages(&quot;package_name&quot;) #e.g. install.packages(&quot;vegan&quot;) Install package from Bioconductor Bioconductor is a free, open source and open development software project for the analysis and comprehension of genomic data generated by wet lab experiments in molecular biology. Packages included in Bioconductor can be installed using the following code: if (!require(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;package_name&quot;) #e.g. BiocManager::install(&quot;DESeq2&quot;) Install package from Github GitHub is a code hosting platform for version control and collaboration. Packages stored in R can be installed using the following code after installing the package devtools: library(devtools) install_github(&quot;github_repository_name_of_the_package&quot;) #e.g. install_github(&quot;anttonalberdi/distillR&quot;) References "],["example-data-statistics.html", "15.2 Example data for statistics", " 15.2 Example data for statistics Contents to be added here. "],["single-omic-analyses.html", "16 Single omic analyses", " 16 Single omic analyses Here is a review of existing methods. "],["data-transformations.html", "17 Data transformations", " 17 Data transformations Here is a review of existing methods. "],["unsupervised-exploration.html", "18 Unsupervised exploration", " 18 Unsupervised exploration Unsupervised methods include exploratory techniques, such as cluster analysis and ordination-based visualisation methods, which reveal the structure and main patterns of the omic datasets without prior information about experimental design. These procedures might reveal that the observations are structured into meaningful groups or that variables can be reduced to fewer dimensions. Researchers can then opt for using the outputs of these analyses, rather than the original multidimensional datasets, for the multi-omic data integration. Most clustering and ordination techniques are computed from association matrices, thus it is essential to do an appropriate pre-transformation of the data and choice of association coefficient, since this influences the final outcome of the analyses Cluster analysis Dimension reduction and ordination "],["cluster-analysis.html", "18.1 Cluster analysis", " 18.1 Cluster analysis Clustering procedures group features or observations into homogeneous sets by minimising within-group and maximising among-group distances 18.1.1 Hierarchical clustering Hierarchical clustering produces a stratified organisation of features or observations where relatively similar objects are grouped together. The clustering can be performed using different criteria to measure the distance between clusters, which will affect the final outcome of the analysis (e.g., single linkage, complete linkage, average linkage and Ward’s minimum variance). #Example code goes here A useful exploratory analysis to reveal general patterns in an omic layer can be obtained by simultaneous application of hierarchical clustering to the rows and columns of the data matrix, and visualising the results in a heatmap. #Example code goes here 18.1.2 Disjoint clustering Disjoint clustering techniques aim at separating the objects into individual, usually mutually exclusive, and in most cases, unconnected clusters. K-means clustering is one of the most typical algorithms where objects are assigned to k clusters using an iterative procedure that minimises the within-clusters sums of squares. Other available clustering methods include twinspan, self-organising maps, dbscan and Dirichlet multinomial mixtures (DMM). DMM were specifically developed to analyse MG data but can be equally useful for other sequencing-based omic datasets. #Example code goes here "],["dimension-reduction-ordination.html", "18.2 Dimension reduction and ordination", " 18.2 Dimension reduction and ordination Ordination is a method complementary to data clustering, which enables displaying differences among samples graphically through reducing the dimensions of the original data set, so that similar objects are near and dissimilar objects are farther from each other. 18.2.1 Principal Component Analysis (PCA) Principal component analysis (PCA) is one of the most widely applied methods for ordination. PCA generates new synthetic variables (principal components) that are linear combinations of the original variables and capture as much variance of the original data as possible. The principal components are orthogonal to each other and correspond to the successive dimensions of maximum variance of the scatter of points. The distance preserved among objects is euclidean and the relationships among variables are linear, thus PCA should generally be applied after appropriate transformations. #Example code goes here 18.2.2 Principal Coordinate Analysis (PCoA) Content to be added here. #Example code goes here 18.2.3 Non-metric Multidimensional Scaling (NMDS) Content to be added here. #Example code goes here 18.2.4 t-Distributed Stochastic Neighbour Embedding (t-SNE) Content to be added here. Requires many data points. #Example code goes here 18.2.5 Uniform manifold approximation and projection (UMAP) Content to be added here. #Example code goes here 18.2.6 Potential of heat diffusion for affinity-based transition embedding (PHATE) Content to be added here. #Example code goes here "],["supervised-analysis.html", "19 Supervised analysis", " 19 Supervised analysis The supervised analyses of omic layers, in contrast to unsupervised ones, incorporate information of experimental design, and can be divided into two types of problems: regression and classification. A regression problem is when the output of the model is a numeric variable or a matrix, such as the phenotypic characteristics of the host or the omic data sets themselves. These methods aim at testing and estimating the effects of the experimental factors (e.g., dietary treatment, drug administration) or variables of interest (e.g., age of the experimental subjects, geographic location of studied populations) on different omic layers, or associating the omic layers with host phenotypic features. A classification problem is when the output of the model is categorical. In the context of multi omic studies, classification methods aim at classifying observations into their experimental groups (e.g. health status, dietary treatment) based on their features on different omic layers. "],["regression-methods.html", "19.1 Regression methods", " 19.1 Regression methods Independently testing the effects of the experimental factors of interest on different omic layers can be very informative to get an overall picture of how the host and the microbiome are responding to the environment and/or the experimental treatment. 19.1.1 PERMANOVA Content to be added here. #Example code goes here 19.1.2 ANOSIM Content to be added here. #Example code goes here 19.1.3 Redundancy analysis (RDA) Content to be added here. #Example code goes here 19.1.4 Canonical Correspondence Analysis (CCA) Content to be added here. #Example code goes here 19.1.5 Generalised linear modelling (GLM) Content to be added here. #Example code goes here 19.1.6 Generalised linear mixed modelling (GLMM) Content to be added here. #Example code goes here "],["classification-methods.html", "19.2 Classification methods", " 19.2 Classification methods It is in classification problems where ML algorithms have proven most useful. 19.2.1 Random Forests (RF) Content to be added here. #Example code goes here 19.2.2 Support Vector Machines (SVM) Content to be added here. #Example code goes here "],["multi-omic-integration.html", "20 Multi-omic integration", " 20 Multi-omic integration Here is a review of existing methods. "],["multi-staged-integration.html", "21 Multi-staged integration", " 21 Multi-staged integration Here is a review of existing methods. "],["meta-dimensional-integration.html", "22 Meta-dimensional integration", " 22 Meta-dimensional integration Here is a review of existing methods. "],["useful-links.html", "23 Useful links", " 23 Useful links Genomics Data Wrangling and Processing for Genomics (website): Shell command line usage Introduction to the Command Line for Genomics (website): general overview of basic command line usage. R usage Intro to R and RStudio for Genomics (website): Efficient R programming (website): best practices for programming in R. Fundamentals of Data Visualization (website): guide to making visualisations that accurately reflect the data, tell a story, and look professional. R Graphics Cookbook (website): a practical guide that provides more than 150 recipes to generate high-quality graphs using ggplot2. Statistics An Introduction to Statistical Learning (book): freely available book about general statistical learning covering regression and classification problems through linear modelling and machine learning. High dimensional statistics with R (website): virtual lesson specialised in dealing with high dimensional data. "],["references.html", "24 References", " 24 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
